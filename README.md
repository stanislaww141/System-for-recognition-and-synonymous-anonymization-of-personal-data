# Система распознавания и синонимического обезличивания персональных данных

В ноутбуке реализована система для русского языка, которая распознает персональные данные в тексте и выполняет их синонимическое обезличивание. В качестве базовой модели используется RuBERT, а для типовых идентификаторов применяются регулярные выражения. Также доступно маскирование найденных сущностей.

## Данные
Используются два источника:
1. **factRuEval-2016** - датасет NER.
2. **`annotations.bio`** - пользовательский BIO-файл с дополнительными ПДн.

Формат `annotations.bio`:
- `токен<TAB>тег` (BIO)
- пустая строка = конец одного текста
- комментарии начинаются с `#`

## Типы сущностей
**BERT-часть:**
- `NAME`, `SURNAME`, `PATRONYMIC`, `LOC_NAME`, `ORG_NAME`
- плюс любые теги, найденные в `annotations.bio`

**Регулярные выражения:**
- `EMAIL`, `INN`, `PHONE`, `PASSPORT`, `CARD`, `SNILS`, `URL`, `MARRIAGE_CERT`, `CADASTRAL`

Есть приоритеты и нормализация пересечений, чтобы вложенные сущности не конфликтовали.

## Обезличивание
Два режима:
1. **Синонимическое обезличивание** - правдоподобные замены с сохранением морфологии:
   - имена/фамилии с сохранением рода и падежа (pymorphy3)
   - email/телефоны/документы с сохранением формата и контрольных разрядов
   - одинаковые значения заменяются одинаково
2. **Маскирование** - замена символов найденных сущностей на `*`.

## Зависимости
Ключевые библиотеки (ставятся в первой ячейке):
- `torch`, `transformers`, `datasets`, `tokenizers`, `accelerate`
- `seqeval`, `scikit-learn`
- `corus`, `pandas`, `numpy`, `tqdm`
- `pymorphy3`, `faker`, `bert-score`

После обучения модель сохраняется в `./res_model_base`.

## Оценка качества
- NER: `seqeval` (precision/recall/F1)
- Семантическая близость: `BERTScore` для сравнения оригинала и обезличенного/замаскированного текста
